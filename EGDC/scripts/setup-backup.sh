#!/bin/bash

# Backup Setup for EGDC
# This script configures automated backups for the EGDC inventory management system

echo "ðŸ’¾ Setting up backup and monitoring for EGDC..."

# Configuration
PROJECT_ID="egdc-test"
INSTANCE_NAME="egdc-inventory-db"
REGION="us-central1"
BACKUP_BUCKET="gs://egdc-backups"
SERVICE_ACCOUNT="egdc-backup@${PROJECT_ID}.iam.gserviceaccount.com"

# Check if gcloud CLI is available
if ! command -v gcloud &> /dev/null; then
    echo "âŒ gcloud CLI is not installed. Please install it first."
    exit 1
fi

echo "ðŸ”§ Configuring backup settings..."

# 1. Create backup bucket
echo "ðŸª£ Creating backup storage bucket..."
gsutil mb -p $PROJECT_ID -c STANDARD -l $REGION $BACKUP_BUCKET 2>/dev/null || echo "Bucket already exists"

# 2. Create service account for backups
echo "ðŸ‘¤ Creating service account for backups..."
gcloud iam service-accounts create egdc-backup \
    --display-name="EGDC Backup Service Account" \
    --description="Service account for automated backups" \
    --project=$PROJECT_ID 2>/dev/null || echo "Service account already exists"

# 3. Grant necessary permissions
echo "ðŸ” Granting permissions..."
gcloud projects add-iam-policy-binding $PROJECT_ID \
    --member="serviceAccount:$SERVICE_ACCOUNT" \
    --role="roles/storage.admin"

gcloud projects add-iam-policy-binding $PROJECT_ID \
    --member="serviceAccount:$SERVICE_ACCOUNT" \
    --role="roles/cloudsql.admin"

# 4. Configure automated backups
echo "ðŸ“… Configuring automated backups..."
gcloud sql instances patch $INSTANCE_NAME \
    --backup-start-time=03:00 \
    --backup-location=$REGION \
    --retained-backups-count=7 \
    --retained-transaction-log-days=7 \
    --project=$PROJECT_ID

# 5. Enable point-in-time recovery
echo "ðŸ”„ Enabling point-in-time recovery..."
gcloud sql instances patch $INSTANCE_NAME \
    --enable-point-in-time-recovery \
    --project=$PROJECT_ID

# 6. Create custom backup script
echo "ðŸ“ Creating custom backup script..."
cat > scripts/backup-database.sh << 'EOF'
#!/bin/bash

# Custom database backup script
# This script creates additional backups beyond the automated Cloud SQL backups

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/tmp/egdc_backups"
PROJECT_ID="egdc-test"
INSTANCE_NAME="egdc-inventory-db"
DATABASE_NAME="egdc_inventory"
BACKUP_BUCKET="gs://egdc-backups"

echo "ðŸ—„ï¸  Creating database backup: $TIMESTAMP"

# Create backup directory
mkdir -p $BACKUP_DIR

# Export database
echo "ðŸ“¤ Exporting database..."
gcloud sql export sql $INSTANCE_NAME $BACKUP_BUCKET/database_backup_$TIMESTAMP.sql \
    --database=$DATABASE_NAME \
    --project=$PROJECT_ID

# Export specific tables
echo "ðŸ“Š Exporting products table..."
gcloud sql export csv $INSTANCE_NAME $BACKUP_BUCKET/products_backup_$TIMESTAMP.csv \
    --database=$DATABASE_NAME \
    --query="SELECT * FROM products ORDER BY created_at DESC" \
    --project=$PROJECT_ID

echo "ðŸ“‹ Exporting change logs..."
gcloud sql export csv $INSTANCE_NAME $BACKUP_BUCKET/change_logs_backup_$TIMESTAMP.csv \
    --database=$DATABASE_NAME \
    --query="SELECT * FROM change_logs WHERE created_at >= NOW() - INTERVAL '7 days' ORDER BY created_at DESC" \
    --project=$PROJECT_ID

# Create backup manifest
echo "ðŸ“‹ Creating backup manifest..."
cat > $BACKUP_DIR/backup_manifest_$TIMESTAMP.json << EOL
{
  "timestamp": "$TIMESTAMP",
  "database": "$DATABASE_NAME",
  "instance": "$INSTANCE_NAME",
  "project": "$PROJECT_ID",
  "files": [
    "database_backup_$TIMESTAMP.sql",
    "products_backup_$TIMESTAMP.csv",
    "change_logs_backup_$TIMESTAMP.csv"
  ],
  "backup_type": "full",
  "retention_days": 30
}
EOL

# Upload manifest
gsutil cp $BACKUP_DIR/backup_manifest_$TIMESTAMP.json $BACKUP_BUCKET/manifests/

# Clean up local files
rm -rf $BACKUP_DIR

echo "âœ… Backup completed: $TIMESTAMP"
echo "ðŸ“ Backup location: $BACKUP_BUCKET"
EOF

chmod +x scripts/backup-database.sh

# 7. Create monitoring script
echo "ðŸ“Š Creating monitoring script..."
cat > scripts/monitor-system.sh << 'EOF'
#!/bin/bash

# System monitoring script for EGDC
# This script checks system health and sends alerts if needed

PROJECT_ID="egdc-test"
INSTANCE_NAME="egdc-inventory-db"
DATABASE_NAME="egdc_inventory"

echo "ðŸ” Monitoring EGDC system health..."

# Check database connectivity
echo "ðŸ“¡ Checking database connectivity..."
if gcloud sql connect $INSTANCE_NAME --user=egdc_user --database=$DATABASE_NAME --quiet <<< "SELECT 1;" > /dev/null 2>&1; then
    echo "âœ… Database connectivity: OK"
else
    echo "âŒ Database connectivity: FAILED"
    # Send alert (implement your alerting mechanism here)
fi

# Check database size
echo "ðŸ’¾ Checking database size..."
DB_SIZE=$(gcloud sql instances describe $INSTANCE_NAME --project=$PROJECT_ID --format="value(settings.dataDiskSizeGb)")
echo "ðŸ“Š Database size: ${DB_SIZE}GB"

# Check backup status
echo "ðŸ”„ Checking backup status..."
LAST_BACKUP=$(gcloud sql backups list --instance=$INSTANCE_NAME --project=$PROJECT_ID --limit=1 --format="value(windowStartTime)")
echo "ðŸ“… Last backup: $LAST_BACKUP"

# Check product count
echo "ðŸ“¦ Checking product count..."
# This would require a connection to the database
# PRODUCT_COUNT=$(psql -h $DB_HOST -U $DB_USER -d $DATABASE_NAME -t -c "SELECT COUNT(*) FROM products;")
# echo "ðŸ”¢ Total products: $PRODUCT_COUNT"

# Check recent changes
echo "ðŸ“ Checking recent changes..."
# RECENT_CHANGES=$(psql -h $DB_HOST -U $DB_USER -d $DATABASE_NAME -t -c "SELECT COUNT(*) FROM change_logs WHERE created_at >= NOW() - INTERVAL '24 hours';")
# echo "ðŸ“Š Changes in last 24h: $RECENT_CHANGES"

# Check disk usage
echo "ðŸ’½ Checking disk usage..."
DISK_USAGE=$(gcloud sql instances describe $INSTANCE_NAME --project=$PROJECT_ID --format="value(settings.dataDiskSizeGb)")
echo "ðŸ“Š Disk usage: ${DISK_USAGE}GB"

# Performance metrics
echo "âš¡ Performance metrics:"
echo "  ðŸ”„ CPU usage: Monitoring via Cloud Console"
echo "  ðŸ§  Memory usage: Monitoring via Cloud Console"
echo "  ðŸ“Š Connection count: Monitoring via Cloud Console"

echo "âœ… System monitoring completed"
EOF

chmod +x scripts/monitor-system.sh

# 8. Create restore script
echo "ðŸ”„ Creating restore script..."
cat > scripts/restore-database.sh << 'EOF'
#!/bin/bash

# Database restore script for EGDC
# This script restores the database from a backup

PROJECT_ID="egdc-test"
INSTANCE_NAME="egdc-inventory-db"
DATABASE_NAME="egdc_inventory"
BACKUP_BUCKET="gs://egdc-backups"

if [ -z "$1" ]; then
    echo "Usage: $0 <backup_file_name>"
    echo "Example: $0 database_backup_20241208_030000.sql"
    exit 1
fi

BACKUP_FILE="$1"

echo "ðŸ”„ Restoring database from backup: $BACKUP_FILE"

# Verify backup file exists
if ! gsutil ls $BACKUP_BUCKET/$BACKUP_FILE > /dev/null 2>&1; then
    echo "âŒ Backup file not found: $BACKUP_BUCKET/$BACKUP_FILE"
    exit 1
fi

# Confirmation prompt
echo "âš ï¸  WARNING: This will overwrite the current database!"
read -p "Are you sure you want to continue? (y/N): " -n 1 -r
echo
if [[ ! $REPLY =~ ^[Yy]$ ]]; then
    echo "âŒ Restore cancelled"
    exit 1
fi

# Import database
echo "ðŸ“¥ Importing database..."
gcloud sql import sql $INSTANCE_NAME $BACKUP_BUCKET/$BACKUP_FILE \
    --database=$DATABASE_NAME \
    --project=$PROJECT_ID

if [ $? -eq 0 ]; then
    echo "âœ… Database restored successfully"
else
    echo "âŒ Database restore failed"
    exit 1
fi

echo "ðŸ”„ Database restore completed"
EOF

chmod +x scripts/restore-database.sh

# 9. Create cleanup script
echo "ðŸ§¹ Creating cleanup script..."
cat > scripts/cleanup-backups.sh << 'EOF'
#!/bin/bash

# Backup cleanup script for EGDC
# This script removes old backups to manage storage costs

BACKUP_BUCKET="gs://egdc-backups"
RETENTION_DAYS=30

echo "ðŸ§¹ Cleaning up old backups..."

# Calculate date threshold
THRESHOLD_DATE=$(date -d "$RETENTION_DAYS days ago" +%Y%m%d)

# List and remove old backups
echo "ðŸ“‹ Listing backups older than $RETENTION_DAYS days..."
gsutil ls -l $BACKUP_BUCKET/ | grep -E "backup_[0-9]{8}_[0-9]{6}" | while read -r line; do
    # Extract filename
    filename=$(echo $line | awk '{print $NF}')
    
    # Extract date from filename
    backup_date=$(echo $filename | grep -o '[0-9]\{8\}' | head -1)
    
    if [ "$backup_date" -lt "$THRESHOLD_DATE" ]; then
        echo "ðŸ—‘ï¸  Removing old backup: $filename"
        gsutil rm $filename
    fi
done

echo "âœ… Backup cleanup completed"
EOF

chmod +x scripts/cleanup-backups.sh

echo "âœ… Backup and monitoring setup completed!"
echo ""
echo "ðŸ“ Created backup scripts:"
echo "  âœ… scripts/backup-database.sh - Manual backup creation"
echo "  âœ… scripts/monitor-system.sh - System health monitoring"
echo "  âœ… scripts/restore-database.sh - Database restore"
echo "  âœ… scripts/cleanup-backups.sh - Backup cleanup"
echo ""
echo "ðŸ”§ Configured features:"
echo "  âœ… Automated daily backups at 3:00 AM"
echo "  âœ… 7-day backup retention"
echo "  âœ… Point-in-time recovery enabled"
echo "  âœ… Backup storage bucket created"
echo "  âœ… Service account configured"
echo ""
echo "ðŸ“… Next steps:"
echo "  1. Set up cron jobs for regular monitoring"
echo "  2. Configure alerting for backup failures"
echo "  3. Test restore procedures"
echo "  4. Set up log monitoring"
echo ""
echo "ðŸ“Š Monitor backups with: gcloud sql backups list --instance=$INSTANCE_NAME"