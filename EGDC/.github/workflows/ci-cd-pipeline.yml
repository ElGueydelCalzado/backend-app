# ENTERPRISE CI/CD PIPELINE
# Automated deployment with quality gates, environment-specific configurations, and zero-downtime deployment

name: EGDC Enterprise CI/CD Pipeline

on:
  push:
    branches: [main, develop, staging]
  pull_request:
    branches: [main, develop]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment'
        required: true
        default: 'staging'
        type: choice
        options:
          - staging
          - production
      skip_tests:
        description: 'Skip test execution'
        required: false
        default: false
        type: boolean

env:
  NODE_VERSION: '18.x'
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # Quality Gates - Static Analysis
  quality-gates:
    name: Quality Gates & Static Analysis
    runs-on: ubuntu-latest
    outputs:
      quality-score: ${{ steps.quality-check.outputs.score }}
      security-score: ${{ steps.security-check.outputs.score }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: TypeScript compilation check
        run: npm run type-check

      - name: ESLint static analysis
        run: npm run lint -- --format=json --output-file=eslint-report.json
        continue-on-error: true

      - name: Security audit
        run: npm audit --audit-level=moderate
        continue-on-error: true

      - name: Code complexity analysis
        run: |
          npx complexity-report --output complexity-report.json --format json src/
        continue-on-error: true

      - name: Quality gate evaluation
        id: quality-check
        run: |
          # Calculate quality score based on various metrics
          ESLINT_ERRORS=$(node -e "const report=require('./eslint-report.json'); console.log(report.reduce((sum,file)=>sum+file.errorCount,0))")
          ESLINT_WARNINGS=$(node -e "const report=require('./eslint-report.json'); console.log(report.reduce((sum,file)=>sum+file.warningCount,0))")
          
          # Quality scoring algorithm
          QUALITY_SCORE=100
          QUALITY_SCORE=$((QUALITY_SCORE - ESLINT_ERRORS * 5))
          QUALITY_SCORE=$((QUALITY_SCORE - ESLINT_WARNINGS * 1))
          QUALITY_SCORE=$((QUALITY_SCORE < 0 ? 0 : QUALITY_SCORE))
          
          echo "score=$QUALITY_SCORE" >> $GITHUB_OUTPUT
          echo "Quality Score: $QUALITY_SCORE"
          
          if [ $QUALITY_SCORE -lt 70 ]; then
            echo "‚ùå Quality gate failed: Score $QUALITY_SCORE < 70"
            exit 1
          fi

      - name: Security gate evaluation
        id: security-check
        run: |
          # Security scoring based on audit results
          SECURITY_SCORE=100
          
          # Check for critical vulnerabilities
          CRITICAL_VULNS=$(npm audit --audit-level=critical --json 2>/dev/null | jq '.metadata.vulnerabilities.critical // 0')
          HIGH_VULNS=$(npm audit --audit-level=high --json 2>/dev/null | jq '.metadata.vulnerabilities.high // 0')
          
          SECURITY_SCORE=$((SECURITY_SCORE - CRITICAL_VULNS * 20))
          SECURITY_SCORE=$((SECURITY_SCORE - HIGH_VULNS * 10))
          SECURITY_SCORE=$((SECURITY_SCORE < 0 ? 0 : SECURITY_SCORE))
          
          echo "score=$SECURITY_SCORE" >> $GITHUB_OUTPUT
          echo "Security Score: $SECURITY_SCORE"
          
          if [ $SECURITY_SCORE -lt 80 ]; then
            echo "‚ùå Security gate failed: Score $SECURITY_SCORE < 80"
            exit 1
          fi

      - name: Upload quality artifacts
        uses: actions/upload-artifact@v4
        with:
          name: quality-reports
          path: |
            eslint-report.json
            complexity-report.json

  # Unit & Integration Tests
  test-suite:
    name: Test Suite Execution
    runs-on: ubuntu-latest
    needs: quality-gates
    if: ${{ !inputs.skip_tests }}
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: egdc_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Setup test database
        run: |
          npm run setup-test-db
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/egdc_test
          REDIS_URL: redis://localhost:6379

      - name: Run unit tests
        run: npm run test:unit -- --coverage --ci
        env:
          NODE_ENV: test
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/egdc_test
          REDIS_URL: redis://localhost:6379

      - name: Run integration tests
        run: npm run test:integration -- --ci
        env:
          NODE_ENV: test
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/egdc_test
          REDIS_URL: redis://localhost:6379

      - name: Run E2E tests
        run: npm run test:e2e -- --ci
        env:
          NODE_ENV: test
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/egdc_test

      - name: Test coverage analysis
        run: |
          COVERAGE=$(npm run test:coverage --silent | grep -o '[0-9]*\.[0-9]*%' | head -1 | sed 's/%//')
          echo "Test coverage: $COVERAGE%"
          
          if (( $(echo "$COVERAGE < 80" | bc -l) )); then
            echo "‚ùå Test coverage below threshold: $COVERAGE% < 80%"
            exit 1
          fi

      - name: Upload test results
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: |
            coverage/
            test-results.xml

  # Build & Package
  build:
    name: Build & Package Application
    runs-on: ubuntu-latest
    needs: [quality-gates, test-suite]
    if: always() && (needs.quality-gates.result == 'success' && (needs.test-suite.result == 'success' || needs.test-suite.result == 'skipped'))
    outputs:
      image-tag: ${{ steps.meta.outputs.tags }}
      image-digest: ${{ steps.build.outputs.digest }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build application
        run: |
          npm run build
        env:
          NODE_ENV: production

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push Docker image
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=registry,ref=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:buildcache
          cache-to: type=registry,ref=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:buildcache,mode=max

      - name: Generate SBOM
        uses: anchore/sbom-action@v0
        with:
          image: ${{ steps.meta.outputs.tags }}
          format: spdx-json
          output-file: sbom.spdx.json

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: |
            .next/
            sbom.spdx.json

  # Security Scanning
  security-scan:
    name: Security Scanning
    runs-on: ubuntu-latest
    needs: build
    steps:
      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ needs.build.outputs.image-tag }}
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: 'trivy-results.sarif'

      - name: Security gate evaluation
        run: |
          # Parse security scan results
          CRITICAL_VULNS=$(cat trivy-results.sarif | jq '.runs[0].results | map(select(.level == "error")) | length')
          HIGH_VULNS=$(cat trivy-results.sarif | jq '.runs[0].results | map(select(.level == "warning")) | length')
          
          echo "Critical vulnerabilities: $CRITICAL_VULNS"
          echo "High vulnerabilities: $HIGH_VULNS"
          
          if [ $CRITICAL_VULNS -gt 0 ]; then
            echo "‚ùå Security gate failed: $CRITICAL_VULNS critical vulnerabilities found"
            exit 1
          fi
          
          if [ $HIGH_VULNS -gt 5 ]; then
            echo "‚ùå Security gate failed: $HIGH_VULNS high vulnerabilities found (threshold: 5)"
            exit 1
          fi

  # Staging Deployment
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [build, security-scan]
    if: github.ref == 'refs/heads/develop' || (github.event_name == 'workflow_dispatch' && inputs.environment == 'staging')
    environment:
      name: staging
      url: https://egdc-staging.vercel.app
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Deploy to Vercel (Staging)
        uses: amondnet/vercel-action@v25
        with:
          vercel-token: ${{ secrets.VERCEL_TOKEN }}
          vercel-org-id: ${{ secrets.VERCEL_ORG_ID }}
          vercel-project-id: ${{ secrets.VERCEL_PROJECT_ID }}
          vercel-args: '--prod'
          scope: ${{ secrets.VERCEL_ORG_ID }}
          alias-domains: egdc-staging.vercel.app

      - name: Run smoke tests on staging
        run: |
          sleep 30 # Wait for deployment to be ready
          
          # Health check
          curl -f https://egdc-staging.vercel.app/api/health || exit 1
          
          # Basic functionality tests
          curl -f https://egdc-staging.vercel.app/api/inventory || exit 1

      - name: Update staging database
        run: |
          # Run database migrations
          npm run db:migrate
        env:
          DATABASE_URL: ${{ secrets.STAGING_DATABASE_URL }}

      - name: Notify team
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          channel: '#deployments'
          text: 'Staging deployment completed successfully! üöÄ'
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}

  # Production Deployment
  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [build, security-scan]
    if: github.ref == 'refs/heads/main' || (github.event_name == 'workflow_dispatch' && inputs.environment == 'production')
    environment:
      name: production
      url: https://egdc.vercel.app
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Pre-deployment backup
        run: |
          # Create database backup before deployment
          echo "Creating pre-deployment backup..."
          # This would integrate with your backup strategy
        env:
          DATABASE_URL: ${{ secrets.PRODUCTION_DATABASE_URL }}

      - name: Deploy to Vercel (Production)
        uses: amondnet/vercel-action@v25
        with:
          vercel-token: ${{ secrets.VERCEL_TOKEN }}
          vercel-org-id: ${{ secrets.VERCEL_ORG_ID }}
          vercel-project-id: ${{ secrets.VERCEL_PROJECT_ID }}
          vercel-args: '--prod'
          scope: ${{ secrets.VERCEL_ORG_ID }}
          alias-domains: egdc.vercel.app

      - name: Zero-downtime deployment validation
        run: |
          # Wait for deployment to be ready
          sleep 60
          
          # Comprehensive health checks
          echo "Running production health checks..."
          
          # API health check
          curl -f https://egdc.vercel.app/api/health || exit 1
          
          # Database connectivity check
          curl -f https://egdc.vercel.app/api/health/database || exit 1
          
          # Integration health checks
          curl -f https://egdc.vercel.app/api/health/integrations || exit 1
          
          # Performance check (response time < 2s)
          RESPONSE_TIME=$(curl -o /dev/null -s -w '%{time_total}' https://egdc.vercel.app/)
          if (( $(echo "$RESPONSE_TIME > 2.0" | bc -l) )); then
            echo "‚ùå Performance check failed: ${RESPONSE_TIME}s > 2.0s"
            exit 1
          fi

      - name: Update production database
        run: |
          # Run database migrations with backup validation
          npm run db:migrate:production
        env:
          DATABASE_URL: ${{ secrets.PRODUCTION_DATABASE_URL }}

      - name: Post-deployment verification
        run: |
          # Run critical business logic tests
          echo "Running post-deployment verification..."
          
          # Test marketplace integrations
          curl -f https://egdc.vercel.app/api/marketplace/health || exit 1
          
          # Test payment gateways
          curl -f https://egdc.vercel.app/api/payments/health || exit 1
          
          # Test inventory sync
          curl -f https://egdc.vercel.app/api/inventory/sync/health || exit 1

      - name: Enable traffic routing
        run: |
          # Enable full traffic to new deployment
          echo "Enabling full traffic routing..."
          # This would integrate with your load balancer/CDN

      - name: Notify stakeholders
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          channel: '#deployments'
          text: 'Production deployment completed successfully! üéâ Version ${{ github.sha }}'
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}

  # Post-deployment monitoring
  post-deployment-monitoring:
    name: Post-deployment Monitoring
    runs-on: ubuntu-latest
    needs: [deploy-staging, deploy-production]
    if: always() && (needs.deploy-staging.result == 'success' || needs.deploy-production.result == 'success')
    steps:
      - name: Setup monitoring checks
        run: |
          # Set up automated monitoring for 24 hours post-deployment
          echo "Setting up post-deployment monitoring..."
          
          # Error rate monitoring
          # Performance monitoring
          # Business metrics monitoring
          
      - name: Generate deployment report
        run: |
          # Generate comprehensive deployment report
          echo "## Deployment Report" > deployment-report.md
          echo "- **Quality Score**: ${{ needs.quality-gates.outputs.quality-score }}/100" >> deployment-report.md
          echo "- **Security Score**: ${{ needs.quality-gates.outputs.security-score }}/100" >> deployment-report.md
          echo "- **Image**: ${{ needs.build.outputs.image-tag }}" >> deployment-report.md
          echo "- **Digest**: ${{ needs.build.outputs.image-digest }}" >> deployment-report.md
          echo "- **Deployment Time**: $(date)" >> deployment-report.md

      - name: Archive deployment artifacts
        uses: actions/upload-artifact@v4
        with:
          name: deployment-report
          path: deployment-report.md
          retention-days: 90